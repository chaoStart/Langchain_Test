import requests
from storage_dataset import storage_financial_data2_es
import os
import openai
from dotenv import load_dotenv

load_dotenv()
os.environ["OPENAI_BASE_URL"] = "http://10.3.24.46:9997/v1"
os.environ["OPENAI_API_KEY"] = "123"
client = openai.Client()

res = client.embeddings.create(input=["æˆ‘æ˜¯ä¸­å›½äºº"], model="bge-large-zh-v1.5")

# è¯·æ±‚åœ°å€
url = "http://10.44.2.104:9090/mainApi/syncplant-business-dataset/api/empoworx/dataset/storeconfig/process"

# è¯·æ±‚æ•°æ®ï¼ˆJSON æ ¼å¼ï¼‰
payload = {
    "code": "",
    "name": "",
    "companyName": "å¤§å”é›†å›¢è‹å·åˆ†å…¬å¸",
    "datasetIds": [],
    "queryType": "1",
    "starttime": "2025-07-16 00:00:00",
    "endtime": "2025-07-16 23:59:59",
    "rowList": [],
    "columnList": [],
    "rowPathList": [],
    "columnParam": {}
}

# è®¾ç½®è¯·æ±‚å¤´ï¼ˆContent-Type ä¸º application/jsonï¼‰
headers = {
    "Content-Type": "application/json"
}


def fetch_data(url, payload, headers):
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()  # æ£€æŸ¥HTTPè¯·æ±‚æ˜¯å¦æˆåŠŸ
        return response.json()
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred: {http_err}")
    except Exception as err:
        print(f"Other error occurred: {err}")


# è·å–åˆå§‹æ•°æ®
data = fetch_data(url, payload, headers)
if not data:
    exit()


def recursion_row_chidren_all(item, name_list):
    if len(item["children"]) != 0:
        name_list.append(item["value"])
        for c in item["children"]:
            recursion_row_chidren_all(c, name_list)
    else:
        name_list.append(item["value"])


def recursion_row_chidren_node(item, name_list):
    # if item["jsonObject"]["dssn"] != "0":
    #     node_leaf = []
    #     recursion_row_chidren_all(item, node_leaf)
    #     node_content = "\n".join(node_leaf)
    #     name_list[item["path"]] = node_content
    # else:
    for i in range(len(item["children"])):
        node_leaf = []
        recursion_row_chidren_all(item["children"][i], node_leaf)
        node_content = "\n".join(node_leaf)
        name_list[item["children"][i]["path"]] = node_content

    # è·å–æ‰€æœ‰çš„sheetå·¥ä½œè¡¨æ•°æ®ï¼Œå³.xlsxæ–‡ä»¶ä¸­æ‰€æœ‰çš„å·¥ä½œè¡¨æ•°æ®é›†ã€‚all_sheet_nameæ˜¯ä¸€ä¸ªlistç±»å‹æ•°æ®


all_sheet_data = data["data"]

# åˆ›å»ºä¸€ä¸ªlistæ•°ç»„ï¼Œç”¨æ¥å­˜å‚¨æ¯ä¸€ä¸ªsheetå·¥ä½œè¡¨çš„è¡Œåˆ—åç§°
all_sheet_list = []
sheet_dict = {}
for each_name in all_sheet_data:
    one_sheet_data = all_sheet_data[each_name]
    company_name = one_sheet_data["ç¼–åˆ¶å•ä½"]
    data_month = one_sheet_data["æ•°æ®ç¼–åˆ¶æ—¶é—´"]
    sheet_name = one_sheet_data["sheetåç§°"]
    table_name = one_sheet_data["æ ‡é¢˜åç§°"]
    column_name = one_sheet_data["columnList"]  # è·å–çš„column_nameæ˜¯Listç±»å‹çš„æ•°ç»„
    big_column_name = " ".join(column_name)
    print("åˆå¹¶åçš„æ€»åˆ—è¡¨åç§°:", big_column_name)
    # è·å–çš„è¡Œæ•°æ®æ˜¯ä¸€ä¸ªliståˆ—è¡¨ç±»å‹çš„æ•°æ®ï¼Œéœ€è¦è¿›ä¸€æ­¥è½¬æ¢ä¸ºæ•´ä¸ªè¡Œæ•°æ®
    if len(one_sheet_data["data"]) != 0:
        row_list_data = one_sheet_data["data"][0]["data"]
    else:
        continue
    if len(row_list_data) != 0:
        # åˆ¤æ–­row_list_data æ˜¯å¦ä¸ºå•ä¸ªç»“ç‚¹ï¼Œå¦‚æœä¸ºå•ä¸ªç»“ç‚¹ï¼Œåˆ™è¿›è¡Œæ·±åº¦è¿­ä»£ï¼Œå¦åˆ™ç›´æ¥è¿›è¡Œè¿­ä»£ï¼›
        if len(row_list_data) == 1:
            for item in row_list_data:  # éå†å·¥ä½œè¡¨ä¸­æ‰€æœ‰èŠ‚ç‚¹ç»„æ•°
                name_list = {}  # èŠ‚ç‚¹è¡Œæ•°æ®é›†å’Œ
                for i in range(len(item["children"])):
                    node_leaf = []
                    recursion_row_chidren_all(item["children"][i], node_leaf)
                    node_content = "\n".join(node_leaf)
                    name_list[item["children"][i]["path"]] = node_content

                for k, v in name_list.items():
                    node_row_name = v
                    row_embedding = client.embeddings.create(input=[v], model="bge-large-zh-v1.5")
                    sheet_dict = {
                        "company_name": company_name,
                        "data_month": data_month,
                        "sheet_name": sheet_name,
                        "table_name": table_name,
                        "row_name": node_row_name,
                        "embedding": row_embedding.data[0].embedding,
                        "column_name": big_column_name
                    }
                    all_sheet_list.append(sheet_dict)
        else:
            name_list = {}  # èŠ‚ç‚¹è¡Œæ•°æ®é›†å’Œ
            for i in range(len(row_list_data)):
                node_leaf = []
                recursion_row_chidren_all(row_list_data[i], node_leaf)
                node_content = "\n".join(node_leaf)
                name_list[row_list_data[i]["path"]] = node_content

            for k, v in name_list.items():
                node_row_name = v
                row_embedding = client.embeddings.create(input=[v], model="bge-large-zh-v1.5")
                sheet_dict = {
                    "company_name": company_name,
                    "data_month": data_month,
                    "sheet_name": sheet_name,
                    "table_name": table_name,
                    "row_name": node_row_name,
                    "embedding": row_embedding.data[0].embedding,
                    "column_name": big_column_name
                }
                all_sheet_list.append(sheet_dict)
    else:
        continue
print("ğŸ§ æˆåŠŸè·å–æ•°æ®é›†çš„sheetå’Œå¯¹åº”çš„æ•´è¡Œæ•´åˆ—åç§°")
storage_financial_data2_es(all_sheet_list)
